{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import PyPDF2\n", "import docx\n", "import cv2\n", "import pytesseract\n", "import re\n", "import string\n", "import numpy as np\n", "import streamlit as st\n", "import pandas as pd\n", "from datetime import datetime\n", "from sentence_transformers import SentenceTransformer, util\n", "import plotly.graph_objects as go\n", "import plotly.express as px\n", "import time\n", "import concurrent.futures\n", "from collections import Counter"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["@st.cache_resource(show_spinner=False)\n", "def load_model():\n", "    return SentenceTransformer('all-MiniLM-L6-v2')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["@st.cache_data(show_spinner=False)\n", "def process_resume(file_content, file_type):\n", "    if file_type == \"application/pdf\":\n", "        return extract_text_from_pdf(file_content)\n", "    elif file_type in [\"application/vnd.openxmlformats-officedocument.wordprocessingml.document\", \"application/msword\"]:\n", "        return extract_text_from_docx(file_content)\n", "    elif file_type.startswith(\"image\"):\n", "        return extract_text_from_image(file_content)\n", "    else:\n", "        raise ValueError(f\"Unsupported file type: {file_type}\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["st_model = load_model()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def extract_text_from_pdf(file):\n", "    try:\n", "        pdf_reader = PyPDF2.PdfReader(file)\n", "        if len(pdf_reader.pages) == 0:\n", "            raise ValueError(\"PDF file appears to be empty\")\n", "        \n", "        text = \"\"\n", "        for page in pdf_reader.pages:\n", "            page_text = page.extract_text()\n", "            if page_text:\n", "                text += page_text + \" \"\n", "        \n", "        if not text.strip():\n", "            raise ValueError(\"No extractable text found in PDF\")\n", "        return text\n", "    except PyPDF2.errors.PdfReadError as e:\n", "        st.error(f\"Invalid or corrupted PDF file: {e}\")\n", "        return \"\"\n", "    except Exception as e:\n", "        st.error(f\"Error extracting PDF: {e}\")\n", "        return \"\""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def extract_text_from_docx(file):\n", "    try:\n", "        doc = docx.Document(file)\n", "        if len(doc.paragraphs) == 0:\n", "            raise ValueError(\"DOCX file appears to be empty\")\n", "        \n", "        full_text = [para.text for para in doc.paragraphs]\n", "        text = \" \".join(full_text)\n", "        \n", "        if not text.strip():\n", "            raise ValueError(\"No extractable text found in DOCX\")\n", "        return text\n", "    except Exception as e:\n", "        st.error(f\"Error extracting DOCX: {e}\")\n", "        return \"\""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def extract_text_from_image(file):\n", "    try:\n", "        file_bytes = np.asarray(bytearray(file.read()), dtype=np.uint8)\n", "        img = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)\n", "        \n", "        if img is None or img.size == 0:\n", "            raise ValueError(\"Invalid image file or empty image\")\n", "        \n", "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n", "        _, binary = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n", "        denoised = cv2.fastNlMeansDenoising(binary, None, 10, 7, 21)\n", "        \n", "        text = pytesseract.image_to_string(denoised)\n", "        \n", "        if not text.strip():\n", "            raise ValueError(\"No text could be extracted from the image\")\n", "        return text\n", "    except Exception as e:\n", "        st.error(f\"Error extracting image: {e}\")\n", "        return \"\""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def basic_preprocess(text):\n", "    text = re.sub(r'\\s+', ' ', text).strip()\n", "    text = re.sub(r'\\n+', '\\n', text)\n", "    processed_text = text.lower()\n", "    translator = str.maketrans('', '', string.punctuation)\n", "    processed_text = processed_text.translate(translator)\n", "    return processed_text"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def extract_keywords(text, job_description):\n", "    words = re.findall(r'\\b[a-zA-Z][a-zA-Z0-9+#]{2,}\\b', text.lower())\n", "    job_words = re.findall(r'\\b[a-zA-Z][a-zA-Z0-9+#]{2,}\\b', job_description.lower())\n", "    \n", "    word_counts = Counter(words)\n", "    job_word_counts = Counter(job_words)\n", "    \n", "    top_resume_words = dict(word_counts.most_common(20))\n", "    \n", "    matching_keywords = set(top_resume_words.keys()) & set(job_word_counts.keys())\n", "    \n", "    return list(matching_keywords), list(top_resume_words.keys())"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def compute_similarity(resume_text, job_description):\n", "    resume_embedding = st_model.encode(resume_text, convert_to_tensor=True)\n", "    job_embedding = st_model.encode(job_description, convert_to_tensor=True)\n", "    similarity_score = util.cos_sim(resume_embedding, job_embedding)\n", "    return similarity_score.item()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def compute_final_score(base_score, boost_points, keyword_match_score=0, boost_weight=0.05):\n", "    keyword_component = keyword_match_score * 0.1\n", "    final_score = base_score + keyword_component + (boost_points * boost_weight)\n", "    return min(final_score, 1.0)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def compute_score_breakdown(base_score, boost_points, keyword_match_score):\n", "    breakdown = {\n", "        \"Skills Matching\": round(0.35 * base_score, 4),\n", "        \"Experience Relevance\": round(0.35 * base_score, 4),\n", "        \"Education Relevance\": round(0.15 * base_score, 4),\n", "        \"Keyword Matching\": round(keyword_match_score * 0.1, 4),\n", "        \"Boost Points\": round(boost_points * 0.05, 4)\n", "    }\n", "    return breakdown"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def generate_improvement_suggestions(final_score, breakdown, text_length, matching_keywords, job_description):\n", "    suggestions = []\n", "    \n", "    if final_score < 0.5:\n", "        suggestions.append(\"Your resume needs significant improvement. Consider adding more relevant skills and experiences.\")\n", "    elif final_score < 0.7:\n", "        suggestions.append(\"Your resume shows potential but could be improved. Tailor it more closely to match the job requirements.\")\n", "    elif final_score < 0.9:\n", "        suggestions.append(\"Your resume is strong! Consider highlighting your key achievements more prominently.\")\n", "    else:\n", "        suggestions.append(\"Excellent resume! Just minor tweaks could make it even better.\")\n", "    \n", "    if text_length < 200:\n", "        suggestions.append(\"Your resume seems too brief. Consider adding more details about your responsibilities and achievements.\")\n", "    elif text_length > 800:\n", "        suggestions.append(\"Your resume is quite lengthy. Consider focusing on the most relevant experiences and skills.\")\n", "    \n", "    if len(matching_keywords) < 5:\n", "        suggestions.append(\"Your resume lacks key terms from the job description. Consider adding more relevant keywords.\")\n", "    \n", "    job_skills = re.findall(r'\\b(?:experience|proficiency|knowledge|familiarity)\\s+(?:with|in|of)?\\s+([A-Za-z0-9+#]+)', job_description)\n", "    if job_skills:\n", "        missing_skills = [skill for skill in job_skills if skill.lower() not in ' '.join(matching_keywords).lower()]\n", "        if missing_skills and len(missing_skills) <= 5:\n", "            suggestions.append(f\"Consider highlighting your experience with: {', '.join(missing_skills[:5])}\")\n", "    \n", "    return suggestions"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def generate_report(candidate_info, preprocessed_text, job_description):\n", "    report = f\"Resume Analysis Report - {candidate_info['Candidate']}\\n\"\n", "    report += f\"Processed on: {candidate_info['Timestamp']}\\n{'-'*50}\\n\\n\"\n", "    \n", "    report += \"SUMMARY\\n\"\n", "    report += f\"Base Similarity Score: {candidate_info['Base Score']:.4f}\\n\"\n", "    report += f\"Keyword Match Score: {candidate_info['Keyword Match Score']:.4f}\\n\"\n", "    report += f\"Manual Boost Points: {candidate_info['Boost Points']}\\n\"\n", "    report += f\"Final Score: {candidate_info['Final Score']:.4f}\\n\"\n", "    report += f\"Word Count: {candidate_info['Word Count']}\\n\\n\"\n", "    \n", "    report += \"SCORE BREAKDOWN\\n\"\n", "    for key, value in candidate_info['Breakdown'].items():\n", "        report += f\"  {key}: {value:.4f}\\n\"\n", "    \n", "    report += \"\\nKEYWORDS ANALYSIS\\n\"\n", "    report += f\"Matching Keywords: {', '.join(candidate_info['Matching Keywords'])}\\n\"\n", "    report += f\"Top Resume Terms: {', '.join(candidate_info['Top Keywords'][:10])}\\n\\n\"\n", "    \n", "    report += \"IMPROVEMENT SUGGESTIONS\\n\"\n", "    for i, s in enumerate(candidate_info['Suggestions'], 1):\n", "        report += f\"{i}. {s}\\n\"\n", "    \n", "    report += \"\\nREFERENCE\\n\"\n", "    report += \"Job Description:\\n\" + job_description + \"\\n\\n\"\n", "    report += \"Preprocessed Resume Text:\\n\" + preprocessed_text + \"\\n\"\n", "    \n", "    return report"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def display_candidate_results(candidate_info, i):\n", "    st.markdown(f\"### {candidate_info['Candidate']}\")\n", "    \n", "    col1, col2 = st.columns(2)\n", "    with col1:\n", "        fig = go.Figure(go.Indicator(\n", "            mode=\"gauge+number\",\n", "            value=candidate_info['Final Score'] * 100,\n", "            domain={'x': [0, 1], 'y': [0, 1]},\n", "            title={'text': \"Final Score (%)\"},\n", "            gauge={\n", "                'axis': {'range': [0, 100]},\n", "                'bar': {'color': \"#1f77b4\"},\n", "                'steps': [\n", "                    {'range': [0, 50], 'color': \"lightgray\"},\n", "                    {'range': [50, 75], 'color': \"gray\"},\n", "                    {'range': [75, 100], 'color': \"lightgreen\"}\n", "                ],\n", "                'threshold': {\n", "                    'line': {'color': \"red\", 'width': 4},\n", "                    'thickness': 0.75,\n", "                    'value': candidate_info['Final Score'] * 100\n", "                }\n", "            }\n", "        ))\n", "        st.plotly_chart(fig, use_container_width=True)\n", "    \n", "    with col2:\n", "        st.subheader(\"Improvement Suggestions\")\n", "        for idx, suggestion in enumerate(candidate_info['Suggestions']):\n", "            st.write(f\"- {suggestion}\", key=f\"cand_{i}_suggestion_{idx}\")\n", "    \n", "    with st.expander(\"Detailed Analysis\"):\n", "        st.subheader(\"Score Breakdown\")\n", "        breakdown_df = pd.DataFrame({\n", "            'Component': list(candidate_info['Breakdown'].keys()),\n", "            'Score': list(candidate_info['Breakdown'].values())\n", "        })\n", "        fig_breakdown = px.bar(breakdown_df, x='Component', y='Score', \n", "                              title=\"Score Components\", color='Score')\n", "        st.plotly_chart(fig_breakdown, use_container_width=True)\n", "        \n", "        st.subheader(\"Keyword Analysis\")\n", "        st.write(\"**Matching Keywords:**\", \", \".join(candidate_info['Matching Keywords']))\n", "        st.write(\"**Top Resume Terms:**\", \", \".join(candidate_info['Top Keywords'][:10]))\n", "        \n", "        st.write(\"**Candidate Name:**\", candidate_info['Candidate'])\n", "        st.write(\"**Base Score:**\", round(candidate_info['Base Score'], 4))\n", "        st.write(\"**Keyword Match Score:**\", round(candidate_info['Keyword Match Score'], 4))\n", "        st.write(\"**Boost Points:**\", candidate_info['Boost Points'])\n", "        st.write(\"**Word Count:**\", candidate_info['Word Count'])\n", "        st.write(\"**Timestamp:**\", candidate_info['Timestamp'])\n", "        \n", "        report_text = generate_report(candidate_info, candidate_info['Preprocessed Text'], candidate_info['Job Description'])\n", "        st.download_button(\"Download Candidate Report\", report_text, \n", "                          file_name=f\"{candidate_info['Candidate']}_Report.txt\", \n", "                          mime=\"text/plain\", key=f\"download_{i}\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def display_comparison(candidate_results):\n", "    if not candidate_results:\n", "        return\n", "        \n", "    df = pd.DataFrame(candidate_results)\n", "    df_sorted = df.sort_values(by=\"Final Score\", ascending=False).reset_index(drop=True)\n", "    best_candidate = df_sorted.iloc[0][\"Candidate\"]\n", "    \n", "    st.subheader(\"Candidate Ranking Comparison\")\n", "    st.write(\"The best candidate is **\" + best_candidate + \"** based on the final score.\")\n", "    \n", "    comparison_df = df_sorted[[\"Candidate\", \"Base Score\", \"Keyword Match Score\", \n", "                               \"Boost Points\", \"Final Score\", \"Word Count\"]]\n", "    st.dataframe(comparison_df)\n", "    \n", "    fig_bar = px.bar(df_sorted, x=\"Candidate\", y=\"Final Score\", color=\"Final Score\",\n", "                    title=\"Final Score Comparison\", text_auto=True)\n", "    fig_bar.update_traces(texttemplate='%{y:.4f}', textposition='outside')\n", "    st.plotly_chart(fig_bar, use_container_width=True)\n", "    \n", "    st.download_button(\n", "        comparison_df.to_csv(index=False).encode('utf-8'),\n", "        file_name=\"resume_comparison_results.csv\",\n", "        mime=\"text/csv\"\n", "    )"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def process_candidate(file, job_description, i):\n", "    try:\n", "        progress_text = f\"Processing {file.name}...\"\n", "        progress_bar = st.progress(0, text=progress_text)\n", "        \n", "        progress_bar.progress(10, text=f\"Extracting text from {file.name}...\")\n", "        file.seek(0)\n", "        file_type = file.type\n", "        candidate_text = process_resume(file, file_type)\n", "        \n", "        if not candidate_text:\n", "            st.error(f\"Failed to extract text from {file.name}\")\n", "            progress_bar.empty()\n", "            return None\n", "            \n", "        progress_bar.progress(30, text=\"Preprocessing text...\")\n", "        candidate_name = file.name.split('.')[0]\n", "        preprocessed_text = basic_preprocess(candidate_text)\n", "        \n", "        progress_bar.progress(50, text=\"Computing similarity...\")\n", "        base_score = compute_similarity(preprocessed_text, job_description)\n", "        \n", "        progress_bar.progress(70, text=\"Extracting keywords...\")\n", "        matching_keywords, top_keywords = extract_keywords(preprocessed_text, job_description)\n", "        keyword_match_score = len(matching_keywords) / max(len(top_keywords), 1) if top_keywords else 0\n", "        \n", "        progress_bar.progress(90, text=\"Generating suggestions...\")\n", "        boost_points = st.slider(f\"Boost Points for {candidate_name}\", \n", "                                min_value=0, max_value=10, value=0, step=1, \n", "                                key=f\"boost_{i}\")\n", "        \n", "        final_score = compute_final_score(base_score, boost_points, keyword_match_score)\n", "        breakdown = compute_score_breakdown(base_score, boost_points, keyword_match_score)\n", "        text_length = len(preprocessed_text.split())\n", "        suggestions = generate_improvement_suggestions(final_score, breakdown, \n", "                                                      text_length, matching_keywords, \n", "                                                      job_description)\n", "        \n", "        timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n", "        \n", "        candidate_info = {\n", "            \"Candidate\": candidate_name,\n", "            \"Base Score\": round(base_score, 4),\n", "            \"Keyword Match Score\": round(keyword_match_score, 4),\n", "            \"Boost Points\": boost_points,\n", "            \"Final Score\": round(final_score, 4),\n", "            \"Word Count\": text_length,\n", "            \"Breakdown\": breakdown,\n", "            \"Suggestions\": suggestions,\n", "            \"Matching Keywords\": matching_keywords,\n", "            \"Top Keywords\": top_keywords,\n", "            \"Timestamp\": timestamp,\n", "            \"Preprocessed Text\": preprocessed_text,\n", "            \"Job Description\": job_description\n", "        }\n", "        \n", "        progress_bar.progress(100, text=\"Complete!\")\n", "        time.sleep(0.5)\n", "        progress_bar.empty()\n", "        \n", "        return candidate_info\n", "        \n", "    except Exception as e:\n", "        st.error(f\"Error processing {file.name}: {e}\")\n", "        return None"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def main():\n", "    st.set_page_config(\n", "        page_title=\"ResumeRise - Empower Your Career\", \n", "        layout=\"wide\",\n", "        initial_sidebar_state=\"expanded\"\n", "    )\n", "    \n", "    st.title(\"ResumeRise\")\n", "    st.header(\"Resume Analysis & Comparison Tool\")\n", "    \n", "    st.markdown(\"\"\"\n", "    ResumeRise helps you analyze and compare candidate resumes against job descriptions. \n", "    Upload multiple resumes, paste a job description, and get detailed insights on each candidate.\n", "    \n", "    **Features:**\n", "    - Extract text from PDF, DOCX, and image files\n", "    - Compute similarity between resumes and job descriptions\n", "    - Extract and match keywords\n", "    - Generate personalized improvement suggestions\n", "    - Compare candidates side-by-side\n", "    - Export comparison results as CSV\n", "    \"\"\")\n", "    \n", "    with st.sidebar:\n", "        st.header(\"Settings\")\n", "        st.write(\"Upload multiple candidate resumes and paste the job description.\")\n", "        \n", "        uploaded_files = st.file_uploader(\n", "            \"Upload Candidate Resumes\", \n", "            type=[\"pdf\", \"docx\", \"jpg\", \"png\"], \n", "            accept_multiple_files=True, \n", "            key=\"file_uploader\"\n", "        )\n", "        \n", "        job_description = st.text_area(\"Paste the Job Description\", height=200, key=\"job_desc\")\n", "        \n", "        st.subheader(\"Analysis Settings\")\n", "        boost_enabled = st.checkbox(\"Enable Manual Boost Points\", value=True)\n", "        \n", "        process_button = st.button(\"Process Resumes\", type=\"primary\", key=\"process_button\")\n", "    \n", "    if uploaded_files and job_description and process_button:\n", "        st.subheader(\"Processing Resumes...\")\n", "        \n", "        if not all(file.size > 0 for file in uploaded_files):\n", "            st.error(\"One or more files appear to be empty. Please check your uploads.\")\n", "            return\n", "        \n", "        total_files = len(uploaded_files)\n", "        overall_progress = st.progress(0, text=f\"Processing 0/{total_files} files...\")\n", "        \n", "        candidate_results = []\n", "        \n", "        for i, file in enumerate(uploaded_files):\n", "            candidate_info = process_candidate(file, job_description, i)\n", "            if candidate_info:\n", "                candidate_results.append(candidate_info)\n", "                display_candidate_results(candidate_info, i)\n", "                st.markdown(\"---\")\n", "            \n", "            overall_progress.progress((i + 1) / total_files, text=f\"Processing {i + 1}/{total_files} files...\")\n", "        \n", "        if len(candidate_results) > 1:\n", "            display_comparison(candidate_results)\n", "        \n", "        if not candidate_results:\n", "            st.warning(\"No valid resumes were processed. Please check your files and try again.\")\n", "        \n", "        overall_progress.empty()\n", "    \n", "    elif not uploaded_files:\n", "        st.info(\"\u00f0\u0178\u2018\u02c6 Upload resumes and paste a job description to get started!\")\n", "        \n", "        with st.expander(\"See an example result\"):\n", "            st.write(\"\"\"\n", "            Example output shows:\n", "            - Candidate score gauge\n", "            - Personalized improvement suggestions\n", "            - Detailed breakdown of scores\n", "            - Keyword matching analysis\n", "            - Comparison between candidates\n", "            \"\"\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if __name__ == \"__main__\":\n", "    main()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}